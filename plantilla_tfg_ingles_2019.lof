\boolfalse {citerequest}\boolfalse {citetracker}\boolfalse {pagetracker}\boolfalse {backtracker}\relax 
\babel@toc {english}{}
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
<<<<<<< HEAD
\contentsline {figure}{\numberline {2.1}{\ignorespaces Difference between traditional machine learning (a) process and feature learning (b) \cite {Pan2010}\relax }}{10}{figure.caption.16}% 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.1}{\ignorespaces First two layers of Audio Set Ontology \cite {Gemmeke2017}\relax }}{16}{figure.caption.22}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.2}{\ignorespaces VGGish architecture\relax }}{21}{figure.caption.29}% 
=======
\contentsline {figure}{\numberline {2.1}{\ignorespaces Movement of the kernel represented as a red block along the width and the height of the original input image. It is clear that it occupies the whole depth of the input image. The arrow indicates an approximation of the movement that the filter follows \cite {Saha2018}.\relax }}{9}{figure.caption.25}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.2}{\ignorespaces Max-pooling operation with a filter size of 2 and a stride of 2 for a single depth filter. Each colour represents a the action portion for each operation \cite {Karpathy2016}\relax }}{10}{figure.caption.27}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.3}{\ignorespaces Representation of a typical CNN model \cite {Hinz2016}\relax }}{11}{figure.caption.28}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {2.4}{\ignorespaces Difference between traditional machine learning (a) process and feature learning (b) \cite {Pan2010}\relax }}{14}{figure.caption.35}% 
>>>>>>> 053a23cd4e128fd4d75264c5ff66f80e9936f8b6
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.3}{\ignorespaces Flowchart about selecting violent classes\relax }}{24}{figure.caption.32}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Confusion matrices\relax }}{27}{figure.caption.36}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.5}{\ignorespaces Architecture to see how the different embeddings work\relax }}{28}{figure.caption.38}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.6}{\ignorespaces t-SNE results from both formats with a legend that shows the labels of the data in the original 128D space\relax }}{30}{figure.caption.39}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.7}{\ignorespaces Visualization of a hyperplane set by \acrshort {svm} and other decision boundaries \cite {Drakos2018}\relax }}{31}{figure.caption.41}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.8}{\ignorespaces Movement of the kernel represented as a red block along the width and the height of the original input image. It is clear that it occupies the whole depth of the input image. The arrow indicates an approximation of the movement that the filter follows \cite {Saha2018}.\relax }}{32}{figure.caption.45}% 
\defcounter {refsection}{0}\relax 
<<<<<<< HEAD
\contentsline {figure}{\numberline {3.9}{\ignorespaces Max-pooling operation with a filter size of 2 and a stride of 2 for a single depth filter. Each colour represents a the action portion for each operation \cite {Karpathy2016}\relax }}{34}{figure.caption.47}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.10}{\ignorespaces Representation of a typical CNN model \cite {Hinz2016}\relax }}{34}{figure.caption.48}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.11}{\ignorespaces Scheme or a recurrent neural network about how the loop works \relax }}{35}{figure.caption.49}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.12}{\ignorespaces Example of long-term dependencies situation. If the predicted output h\textsubscript {n-1} depends on x\textsubscript {0} and x\textsubscript {1}, the vanishing gradient problem may appear.\relax }}{36}{figure.caption.50}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.13}{\ignorespaces LSTM module with the representation of the different operations that take place inside of it\relax }}{37}{figure.caption.51}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.14}{\ignorespaces Step 1. Forget gate\relax }}{37}{figure.caption.52}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.15}{\ignorespaces Step 2. Input gate\relax }}{37}{figure.caption.53}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.16}{\ignorespaces Step 3. Update cell state\relax }}{38}{figure.caption.54}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.17}{\ignorespaces Step 3. Output gate\relax }}{39}{figure.caption.55}% 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.1}{\ignorespaces Bar plot that shows the number of samples for each of the selected classes. Clearly, the violent categories are much less populated than the others, that did not have to much any semantic criteria\relax }}{42}{figure.caption.58}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.2}{\ignorespaces Number of observations for train, validation and test subsets used in the different experiments\relax }}{43}{figure.caption.59}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.3}{\ignorespaces Confusion matrices for SVM multiclass classification for train and validation sets\relax }}{44}{figure.caption.61}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Confusion matrices for SVM multiclass classification for train and validation sets\relax }}{45}{figure.caption.62}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Confusion matrix for the test set for the SVM multiclass classification\relax }}{45}{figure.caption.63}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Accuracy values for the three sets for the SVM multiclass classification\relax }}{46}{figure.caption.64}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.7}{\ignorespaces Confusion matrices for SVM multiclass + SVM binary classification\relax }}{47}{figure.caption.65}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.8}{\ignorespaces Confusion matrix for the test set for the SVM multiclass + SVM binary classification\relax }}{48}{figure.caption.66}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.9}{\ignorespaces Accuracy values for the three sets for the SVM multiclass + SVM binary classification\relax }}{49}{figure.caption.67}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.10}{\ignorespaces Architecture for the LSTM multiclass classifier implementation\relax }}{49}{figure.caption.68}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.11}{\ignorespaces Confusion matrices for LSTM multiclass classification for train and validation sets\relax }}{50}{figure.caption.70}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.12}{\ignorespaces Confusion matrix for the test set for the LSTM multiclass classification\relax }}{51}{figure.caption.71}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.13}{\ignorespaces Accuracy values for the three sets for the LSTM multiclass classification\relax }}{51}{figure.caption.72}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.14}{\ignorespaces Confusion matrices for LSTM multiclass + SVM binary classification\relax }}{52}{figure.caption.73}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.15}{\ignorespaces Confusion matrix for the test set for the LSTM multiclass + SVM binary classification\relax }}{53}{figure.caption.74}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.16}{\ignorespaces Accuracy values for the three sets for the LSTM multiclass + SVM binary classification\relax }}{53}{figure.caption.75}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.17}{\ignorespaces Confusion matrices for CNN multiclass classification for train and validation sets\relax }}{54}{figure.caption.76}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.18}{\ignorespaces Confusion matrix for the test set for the CNN multiclass classification\relax }}{55}{figure.caption.77}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.19}{\ignorespaces Accuracy values for the three sets for the CNN multiclass classification\relax }}{55}{figure.caption.78}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.20}{\ignorespaces Confusion matrices for CNN multiclass + SVM binary classification\relax }}{56}{figure.caption.79}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.21}{\ignorespaces Confusion matrix for the test set for the CNN multiclass + SVM binary classification\relax }}{57}{figure.caption.80}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.22}{\ignorespaces Accuracy values for the three sets for the CNN multiclass + SVM binary classification\relax }}{57}{figure.caption.81}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.23}{\ignorespaces Test confusion matrices\relax }}{60}{figure.caption.84}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {24}{\ignorespaces Example of confusion matrix\relax }}{}{figure.caption.90}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {25}{\ignorespaces Confusion matrix for a multiclass classification \cite {Kruger2018}\relax }}{}{figure.caption.91}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {26}{\ignorespaces K-fold cross-validation scheme. The data is first split into train and test, and then the train is split again with this method \cite {Scikit-learna}\relax }}{}{figure.caption.92}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {27}{\ignorespaces Cross-entropy loss function when the true label is equals to 1. As the probability of the predicted class approaches to 1, the loss function tends to zero. However, if it the probability is closer to 0.0, then the loss function increases heavily \cite {MLGlossary2017}.\relax }}{}{figure.caption.93}% 
=======
\contentsline {figure}{\numberline {3.1}{\ignorespaces First two layers of Audio Set Ontology \cite {Gemmeke2017}\relax }}{20}{figure.caption.49}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.2}{\ignorespaces VGGish architecture\relax }}{25}{figure.caption.61}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.3}{\ignorespaces Flowchart about selecting violent classes\relax }}{28}{figure.caption.68}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.4}{\ignorespaces Confusion matrices\relax }}{31}{figure.caption.72}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.5}{\ignorespaces Architecture to see how the different embeddings work\relax }}{32}{figure.caption.74}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.6}{\ignorespaces t-SNE results from both formats with a legend that shows the labels of the data in the original 128D space\relax }}{34}{figure.caption.75}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {3.7}{\ignorespaces Visualization of a hyperplane set by \acrshort {svm} and other decision boundaries \cite {Drakos2018}\relax }}{35}{figure.caption.78}% 
\defcounter {refsection}{0}\relax 
\addvspace {10\p@ }
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.1}{\ignorespaces Bar plot that shows the number of samples for each of the selected classes. Clearly, the violent categories are much less populated than the others, that did not have to much any semantic criteria\relax }}{38}{figure.caption.83}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.2}{\ignorespaces Number of observations for train, validation and test subsets used in the different experiments\relax }}{39}{figure.caption.84}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.3}{\ignorespaces SVM multiclass classifier whole model. \textit {X} is the input data that can be from train, validation or test set. \textit {\^{Y}} is the predicting labels for \textit {X}.\relax }}{40}{figure.caption.86}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.4}{\ignorespaces Confusion matrices for SVM multiclass classification for train and validation sets\relax }}{41}{figure.caption.87}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.5}{\ignorespaces Confusion matrix for the test set for the SVM multiclass classification\relax }}{42}{figure.caption.88}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.6}{\ignorespaces Accuracy values for the three sets for the SVM multiclass classification\relax }}{42}{figure.caption.89}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.7}{\ignorespaces Example of confusion matrix\relax }}{}{figure.caption.94}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.8}{\ignorespaces Confusion matrix for a multiclass classification \cite {Kruger2018}\relax }}{}{figure.caption.95}% 
\defcounter {refsection}{0}\relax 
\contentsline {figure}{\numberline {4.9}{\ignorespaces K-fold cross-validation scheme. The data is first split into train and test, and then the train is split again with this method \cite {Scikit-learna}\relax }}{}{figure.caption.96}% 
>>>>>>> 053a23cd4e128fd4d75264c5ff66f80e9936f8b6
\contentsfinish 
\contentsfinish 
