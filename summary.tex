% !TeX spellcheck = en_GB
	Nowadays, the availability of every kind of data has made possible the development and implementation of different systems in order to learn pattern and behaviours so useful information can be extracted in order to apply solutions to real world problems. This branch of study is known as machine learning. Within these data, a field of research that has largely evolved during the last years is the one related to image and audio learning. Since all the multimedia resources that are currently available, this type of data has become one of the principal sources of knowledge to transform in successful results for several situations. Some examples for the works belonging to this field are speech recognition, \acrfull{mir}, \acrfull{med}, \acrfull{asc}, \acrfull{aedc}.
	
	One of the tasks that has been treated as well is the \acrfull{avd}. An example of a common application for this research line is related to the detection of violence in videos or movies in order to categorize them as appropriate content for children. Also, several works have been done related to video surveillance topic. Our purpose is to work in a new branch related to violence against women, more specifically, in gender-based violence centered in \acrfull{ipv}. For this reason the \textit{UC3M4Safety Team} has been worked together with other groups in what is called EMPATIA-TC\footnote{\textit{protEcciónn integral de las víctimas de violencia de género Mediante comPutaciónn AfecTIva multimodAl} funded by Department  of  Research  and Innovation of Madrid Regional Authority, in the EMPATIA-CM research project(reference  Y2018/TCS-5046)} project, so as to develop a protocol to implement machine learning methods to prevent this type of actions. 
	
	As a contribution to the project, the task of classifying audio events trying to distinguish between violent and non-violent has been addressed in this work. In order to collect the necessary amount and type of data, we decided to work with \textit{AudioSet} database, which is formed by around 2 million annotated videos and a total of 527 classes. Also, we wanted to define a new concept for gender-based violence applied to a certain victims' situation by developing a system in which the user can select the type of categories that are more common in her daily violent situations. So the classes considered in the classification task can be personalized. 
	
	In order to characterize the data selected, we attempted to find a feature extraction method that differs from the most common descriptors called \acrfull{lld}, that allow us to find a feature space in which violent events were easier to differentiate. With this purpose, we have used a novel type of feature that can be obtained by running \acrshort{dnn} algorithms with the desired data, called \textit{embeddings}. These are extracted by making use of the \textit{transfer learning} concept with the \acrshort{cnn} model designed by Google and proposed with Audio Set database named as \textit{\acrshort{vgg}ish}.
	
	For the implementation task, we have taken advantaged of different algorithms as \acrshort{svm}, \acrshort{cnn} and \acrshort{lstm}. We have tried them in a multiclass classification with monolabel data and then use them in a preprocessing stage for a posterior binary classification between violent and non-violent events performed with a \acrshort{svm} classifier.
	
	