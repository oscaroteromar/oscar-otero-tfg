% !TeX spellcheck = en_GB
	Nowadays, the availability of big data resources has allowed the development and implementation of different algorithms to learn patterns and behaviours. Useful information can be extracted from data in order to find solutions to real world problems. This branch of study is known as machine learning. Within this field, an area of research that has largely evolved during the last years is the one related to image and audio learning. Given the multimedia resources that are currently available, this type of data has become one of the main sources of knowledge with a potential to be transformed in successful results for several situations. Some examples for the works belonging to this field are speech recognition, \acrfull{mir}, \acrfull{med}, \acrfull{asc}, \acrfull{aedc}.
	
	One of the tasks that has been considered is the \acrfull{avd}. An example of a common application for this research line is related to the detection of violence in videos or movies in order to categorize them appropriately for parental control. Also, several works have been done related to video surveillance topic. Our purpose is to work in a new branch related to violence against women, more specifically, in gender-based violence centered in \acrfull{ipv}. For this reason the \textit{UC3M4Safety Team} has been created as a joint effort from a handful of research groups in a project called EMPATIA\footnote{\textit{protEcciónn integral de las víctimas de violencia de género Mediante comPutaciónn AfecTIva multimodAl}, funded by Department  of  Research  and Innovation of Madrid Regional Government (Y2018/TCS-5046)}. Its aim is %, in the EMPATIA-CM  project, so as 
	to develop a protocol to implement machine learning methods to prevent this type of actions. 
	
	As a contribution to the project, the task of classifying audio events trying to distinguish between violent and non-violent has been addressed in this work. In order to collect the necessary amount and type of data, we decided to work with \textit{AudioSet} database, which comprises around 2 million annotated videos and a total of 527 classes. Also, we wanted to define a new concept for gender-based violence applied to a certain victims' situation by developing a system in which the user can select the type of categories that are more common in her daily violent situations. So the classes considered in the classification task can be personalized. 
	
	In order to characterize the data selected, we attempted to find a robust feature extraction method that goes beyond \acrfull{lld}, that allow us to find a feature space in which violent events were easier to distinguish. With this purpose, we have used a novel type of feature that can be obtained by running deep learning algorithms with the desired data, also known as \textit{embeddings}. These are extracted by making use of the \textit{transfer learning} concept with the \acrshort{cnn} model designed by Google and trained with the Audio Set database named as \textit{\acrshort{vgg}ish}.
	
	For the classification task, we have taken advantage of different algorithms as \acrshort{svm}, \acrshort{cnn} and \acrshort{lstm}. We have tried them in a multiclass classification with single label data and then use them in a preprocessing stage for a posterior binary classification between violent and non-violent events performed with a simple \acrshort{svm} classifier.
	
	